{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e169c078",
   "metadata": {},
   "source": [
    "\n",
    "# Лабораторная работа №2 - исследования с логистической и линейной регрессией  \n",
    "\n",
    "В этом ноутбуке выполняются пункты **2–4**:\n",
    "- **2. Создание бейзлайна и оценка качества** (sklearn)\n",
    "- **3. Улучшение бейзлайна** (гипотезы → проверка → улучшенный бейзлайн)\n",
    "- **4. Имплементация алгоритмов** (с нуля) + сравнения\n",
    "\n",
    "## Открытые датасеты по ссылке (UCI)\n",
    "- **Классификация (логистическая регрессия):** Banknote Authentication  \n",
    "  `https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt`\n",
    "- **Регрессия (линейная регрессия):** Auto MPG  \n",
    "  `https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e69e5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Literal, Tuple\n",
    "import inspect\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# Версия-агностичный OneHotEncoder (чтобы не ловить предупреждения/ошибки из-за sparse/sparse_output)\n",
    "def make_ohe_dense():\n",
    "    sig = inspect.signature(OneHotEncoder)\n",
    "    if \"sparse_output\" in sig.parameters:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172429e",
   "metadata": {},
   "source": [
    "\n",
    "## Загрузка данных (по ссылке)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa1c5906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zerotonyq\\AppData\\Local\\Temp\\ipykernel_5792\\959624252.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_reg = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model_year  origin                   car_name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banknote shape: (1372, 5)\n",
      "Auto MPG shape: (398, 9)\n",
      "\n",
      "Missing (Auto MPG):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_year</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car_name</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              missing\n",
       "mpg                 0\n",
       "cylinders           0\n",
       "displacement        0\n",
       "horsepower          6\n",
       "weight              0\n",
       "acceleration        0\n",
       "model_year          0\n",
       "origin              0\n",
       "car_name            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Banknote Authentication (classification) =====\n",
    "banknote_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
    "banknote_cols = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
    "df_cls = pd.read_csv(banknote_url, header=None, names=banknote_cols)\n",
    "\n",
    "# ===== Auto MPG (regression) =====\n",
    "auto_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "auto_cols = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\", \"car_name\"]\n",
    "df_reg = pd.read_csv(\n",
    "    auto_url,\n",
    "    delim_whitespace=True,\n",
    "    header=None,\n",
    "    names=auto_cols,\n",
    "    na_values=\"?\"\n",
    ")\n",
    "\n",
    "display(df_cls.head())\n",
    "display(df_reg.head())\n",
    "\n",
    "print(\"Banknote shape:\", df_cls.shape)\n",
    "print(\"Auto MPG shape:\", df_reg.shape)\n",
    "print(\"\\nMissing (Auto MPG):\")\n",
    "display(df_reg.isna().sum().to_frame(\"missing\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ce602",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Создание бейзлайна и оценка качества (sklearn)\n",
    "\n",
    "### 2.1 Разбиение train/test\n",
    "- Классификация: stratify по классам.\n",
    "- Регрессия: обычное разбиение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa34d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls train/test: (1097, 4) (275, 4)\n",
      "reg train/test: (318, 7) (80, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Classification =====\n",
    "X_cls = df_cls.drop(columns=[\"class\"]).values\n",
    "y_cls = df_cls[\"class\"].values\n",
    "\n",
    "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(\n",
    "    X_cls, y_cls,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_cls\n",
    ")\n",
    "\n",
    "# ===== Regression =====\n",
    "# car_name убираем (строковый признак)\n",
    "df_reg_base = df_reg.drop(columns=[\"car_name\"]).copy()\n",
    "X_reg = df_reg_base.drop(columns=[\"mpg\"])\n",
    "y_reg = df_reg_base[\"mpg\"]\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"cls train/test:\", X_cls_train.shape, X_cls_test.shape)\n",
    "print(\"reg train/test:\", X_reg_train.shape, X_reg_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528aae3c",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Бейзлайн: LogisticRegression и LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd319b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (classification): {'accuracy': 0.9854545454545455, 'f1_macro': 0.9853129673146763, 'roc_auc': 1.0}\n",
      "Baseline (regression): {'mae': 2.2556437614709393, 'rmse': 2.8632413432253987, 'r2': 0.8475229080116502}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Baseline: Logistic Regression (без масштабирования) =====\n",
    "logreg_base = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)  # L2 по умолчанию\n",
    "logreg_base.fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred = logreg_base.predict(X_cls_test)\n",
    "y_cls_proba = logreg_base.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_base = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba),\n",
    "}\n",
    "print(\"Baseline (classification):\", cls_metrics_base)\n",
    "\n",
    "# ===== Baseline: Linear Regression (простая импутация, origin как число 1/2/3) =====\n",
    "linreg_base = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"model\", LinearRegression()),\n",
    "])\n",
    "linreg_base.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred = linreg_base.predict(X_reg_test)\n",
    "\n",
    "reg_metrics_base = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred),\n",
    "}\n",
    "print(\"Baseline (regression):\", reg_metrics_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e23dd",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Улучшение бейзлайна\n",
    "\n",
    "### 3.1 Гипотезы улучшения\n",
    "\n",
    "**Классификация (логистическая регрессия):**\n",
    "1. Масштабирование признаков (StandardScaler) улучшит стабильность оптимизации и качество.\n",
    "2. Подбор гиперпараметров регуляризации `C` и опции `class_weight` через GridSearchCV даст прирост.\n",
    "\n",
    "**Регрессия (линейная регрессия):**\n",
    "1. `origin` лучше трактовать как категориальный признак → one-hot.\n",
    "2. Полиномиальные признаки для числовых признаков (degree=2) могут описать нелинейности и улучшить качество.\n",
    "3. Всё делаем через Pipeline/ColumnTransformer (корректно для CV).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4375525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (classification): {'model__C': 100.0, 'model__class_weight': None, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n",
      "CV best f1_macro: 0.9907798248452744\n",
      "Improved (classification): {'accuracy': 0.9854545454545455, 'f1_macro': 0.9853129673146763, 'roc_auc': 1.0}\n",
      "Best params (regression): {'prep__num__poly__degree': 2}\n",
      "CV best (neg RMSE): -3.0905953958424885\n",
      "Improved (regression): {'mae': 1.9208929326477182, 'rmse': 2.5975633128805686, 'r2': 0.8745065752201051}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zerotonyq\\Desktop\\ML\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>improved</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.255644</td>\n",
       "      <td>2.863241</td>\n",
       "      <td>0.847523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.920893</td>\n",
       "      <td>2.597563</td>\n",
       "      <td>0.874507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task     stage  accuracy  f1_macro  roc_auc       mae      rmse  \\\n",
       "0  classification  baseline  0.985455  0.985313      1.0       NaN       NaN   \n",
       "1  classification  improved  0.985455  0.985313      1.0       NaN       NaN   \n",
       "2      regression  baseline       NaN       NaN      NaN  2.255644  2.863241   \n",
       "3      regression  improved       NaN       NaN      NaN  1.920893  2.597563   \n",
       "\n",
       "         r2  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2  0.847523  \n",
       "3  0.874507  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Improved: Classification (scaler + tuning) =====\n",
    "cls_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=3000, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "cls_param_grid = {\n",
    "    \"model__C\": [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    \"model__class_weight\": [None, \"balanced\"],\n",
    "    \"model__solver\": [\"lbfgs\"],   # совместимо с L2\n",
    "    \"model__penalty\": [\"l2\"],\n",
    "}\n",
    "\n",
    "cv_cls = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cls_search = GridSearchCV(\n",
    "    cls_pipe,\n",
    "    cls_param_grid,\n",
    "    cv=cv_cls,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "cls_search.fit(X_cls_train, y_cls_train)\n",
    "\n",
    "print(\"Best params (classification):\", cls_search.best_params_)\n",
    "print(\"CV best f1_macro:\", cls_search.best_score_)\n",
    "\n",
    "logreg_best = cls_search.best_estimator_\n",
    "y_cls_pred_best = logreg_best.predict(X_cls_test)\n",
    "y_cls_proba_best = logreg_best.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_best = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_best),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_best, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_best),\n",
    "}\n",
    "print(\"Improved (classification):\", cls_metrics_best)\n",
    "\n",
    "\n",
    "# ===== Improved: Regression (one-hot + polynomial + CV) =====\n",
    "num_cols = [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\"]\n",
    "cat_cols = [\"origin\"]\n",
    "\n",
    "reg_preprocess = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"poly\", PolynomialFeatures(include_bias=False))  # степень подберём\n",
    "    ]), num_cols),\n",
    "    (\"cat\", make_ohe_dense(), cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    (\"prep\", reg_preprocess),\n",
    "    (\"model\", LinearRegression()),\n",
    "])\n",
    "\n",
    "reg_param_grid = {\n",
    "    \"prep__num__poly__degree\": [1, 2],\n",
    "}\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "reg_search = GridSearchCV(\n",
    "    reg_pipe,\n",
    "    reg_param_grid,\n",
    "    cv=cv_reg,\n",
    "    scoring=\"neg_root_mean_squared_error\",  # ВАЖНО: правильное имя метрики\n",
    "    n_jobs=-1\n",
    ")\n",
    "reg_search.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "print(\"Best params (regression):\", reg_search.best_params_)\n",
    "print(\"CV best (neg RMSE):\", reg_search.best_score_)\n",
    "\n",
    "linreg_best = reg_search.best_estimator_\n",
    "y_reg_pred_best = linreg_best.predict(X_reg_test)\n",
    "\n",
    "reg_metrics_best = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_best),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_best),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_best),\n",
    "}\n",
    "print(\"Improved (regression):\", reg_metrics_best)\n",
    "\n",
    "compare = pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"stage\": \"baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"improved\", **cls_metrics_best},\n",
    "    {\"task\": \"regression\", \"stage\": \"baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"improved\", **reg_metrics_best},\n",
    "])\n",
    "display(compare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a35a65",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Имплементация алгоритмов (с нуля)\n",
    "\n",
    "Реализуем:\n",
    "- **Логистическую регрессию** (бинарная классификация) через градиентный спуск.\n",
    "- **Линейную регрессию** через нормальное уравнение (pseudoinverse).\n",
    "\n",
    "Далее:\n",
    "- сравниваем кастомные модели с бейзлайном (п.2),\n",
    "- добавляем техники улучшенного бейзлайна (п.3) и сравниваем с улучшенным (п.3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04185b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)  # защита от overflow\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, lr: float = 0.1, n_iters: int = 5000, l2: float = 0.0, fit_intercept: bool = True):\n",
    "        self.lr = float(lr)\n",
    "        self.n_iters = int(n_iters)\n",
    "        self.l2 = float(l2)\n",
    "        self.fit_intercept = bool(fit_intercept)\n",
    "        self.w_ = None\n",
    "\n",
    "    def _add_intercept(self, X):\n",
    "        if not self.fit_intercept:\n",
    "            return X\n",
    "        return np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        Xb = self._add_intercept(X)\n",
    "\n",
    "        n, d = Xb.shape\n",
    "        self.w_ = np.zeros(d, dtype=float)\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            p = sigmoid(Xb @ self.w_)\n",
    "            # градиент логлосса + L2 (не регуляризуем bias)\n",
    "            grad = (Xb.T @ (p - y)) / n\n",
    "            if self.l2 > 0:\n",
    "                reg = self.l2 * self.w_\n",
    "                if self.fit_intercept:\n",
    "                    reg[0] = 0.0\n",
    "                grad += reg / n\n",
    "            self.w_ -= self.lr * grad\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        Xb = self._add_intercept(X)\n",
    "        p1 = sigmoid(Xb @ self.w_)\n",
    "        return np.vstack([1 - p1, p1]).T\n",
    "\n",
    "    def predict(self, X, threshold: float = 0.5):\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= threshold).astype(int)\n",
    "\n",
    "\n",
    "class LinearRegressionCustom:\n",
    "    def __init__(self, fit_intercept: bool = True):\n",
    "        self.fit_intercept = bool(fit_intercept)\n",
    "        self.w_ = None\n",
    "\n",
    "    def _add_intercept(self, X):\n",
    "        if not self.fit_intercept:\n",
    "            return X\n",
    "        return np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        Xb = self._add_intercept(X)\n",
    "        # w = pinv(X) y\n",
    "        self.w_ = np.linalg.pinv(Xb) @ y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        Xb = self._add_intercept(X)\n",
    "        return Xb @ self.w_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1828e13",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Кастомные модели vs бейзлайн (пункт 2)\n",
    "\n",
    "Для честности сравнения в “кастом-бейзлайне” используем те же входы:\n",
    "- Классификация: сырые признаки без масштабирования.\n",
    "- Регрессия: импутация медианой, origin как число.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf21291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom baseline (classification): {'accuracy': 0.9854545454545455, 'f1_macro': 0.9853129673146763, 'roc_auc': 1.0}\n",
      "Custom baseline (regression): {'mae': 2.25564376147094, 'rmse': 2.8632413432254054, 'r2': 0.8475229080116495}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.255644</td>\n",
       "      <td>2.863241</td>\n",
       "      <td>0.847523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.255644</td>\n",
       "      <td>2.863241</td>\n",
       "      <td>0.847523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task             model  accuracy  f1_macro  roc_auc       mae  \\\n",
       "0  classification  sklearn_baseline  0.985455  0.985313      1.0       NaN   \n",
       "1  classification   custom_baseline  0.985455  0.985313      1.0       NaN   \n",
       "2      regression  sklearn_baseline       NaN       NaN      NaN  2.255644   \n",
       "3      regression   custom_baseline       NaN       NaN      NaN  2.255644   \n",
       "\n",
       "       rmse        r2  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2  2.863241  0.847523  \n",
       "3  2.863241  0.847523  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Custom baseline: classification (без scaler) =====\n",
    "custom_log_base = LogisticRegressionCustom(lr=0.1, n_iters=8000, l2=0.0, fit_intercept=True)\n",
    "custom_log_base.fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred_c = custom_log_base.predict(X_cls_test)\n",
    "y_cls_proba_c = custom_log_base.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_custom_base = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_c),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_c, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_c),\n",
    "}\n",
    "print(\"Custom baseline (classification):\", cls_metrics_custom_base)\n",
    "\n",
    "# ===== Custom baseline: regression (impute median) =====\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "Xr_train_imp = imp.fit_transform(X_reg_train)\n",
    "Xr_test_imp = imp.transform(X_reg_test)\n",
    "\n",
    "custom_lin_base = LinearRegressionCustom(fit_intercept=True).fit(Xr_train_imp, y_reg_train.values)\n",
    "y_reg_pred_c = custom_lin_base.predict(Xr_test_imp)\n",
    "\n",
    "reg_metrics_custom_base = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_c),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_c),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_c),\n",
    "}\n",
    "print(\"Custom baseline (regression):\", reg_metrics_custom_base)\n",
    "\n",
    "display(pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"model\": \"sklearn_baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"model\": \"custom_baseline\", **cls_metrics_custom_base},\n",
    "    {\"task\": \"regression\", \"model\": \"sklearn_baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"model\": \"custom_baseline\", **reg_metrics_custom_base},\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ada9a1",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Добавляем техники улучшенного бейзлайна (пункт 3) к кастомным моделям\n",
    "\n",
    "**Классификация:** StandardScaler + лучшие гиперпараметры `C`/`class_weight`.  \n",
    "**Регрессия:** one-hot(origin) + scaling + polynomial degree (лучший) через тот же препроцессор.\n",
    "\n",
    "> Примечание: `C` в sklearn - это обратная сила регуляризации. В кастомной реализации используем приближение `l2 ≈ 1/C` (достаточно для лабораторной).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ca27ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom improved (classification): {'accuracy': 0.9709090909090909, 'f1_macro': 0.9707041653350379, 'roc_auc': 1.0}\n",
      "Custom improved (regression): {'mae': 1.9208929326477402, 'rmse': 2.5975633128805558, 'r2': 0.8745065752201063}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_improved</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.985313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_improved</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.970704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.255644</td>\n",
       "      <td>2.863241</td>\n",
       "      <td>0.847523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.920893</td>\n",
       "      <td>2.597563</td>\n",
       "      <td>0.874507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.255644</td>\n",
       "      <td>2.863241</td>\n",
       "      <td>0.847523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.920893</td>\n",
       "      <td>2.597563</td>\n",
       "      <td>0.874507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task             stage  accuracy  f1_macro  roc_auc       mae  \\\n",
       "0  classification  sklearn_baseline  0.985455  0.985313      1.0       NaN   \n",
       "1  classification  sklearn_improved  0.985455  0.985313      1.0       NaN   \n",
       "2  classification   custom_baseline  0.985455  0.985313      1.0       NaN   \n",
       "3  classification   custom_improved  0.970909  0.970704      1.0       NaN   \n",
       "4      regression  sklearn_baseline       NaN       NaN      NaN  2.255644   \n",
       "5      regression  sklearn_improved       NaN       NaN      NaN  1.920893   \n",
       "6      regression   custom_baseline       NaN       NaN      NaN  2.255644   \n",
       "7      regression   custom_improved       NaN       NaN      NaN  1.920893   \n",
       "\n",
       "       rmse        r2  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4  2.863241  0.847523  \n",
       "5  2.597563  0.874507  \n",
       "6  2.863241  0.847523  \n",
       "7  2.597563  0.874507  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Custom improved: classification (scaler + best params) =====\n",
    "best_C = cls_search.best_params_[\"model__C\"]\n",
    "best_class_weight = cls_search.best_params_[\"model__class_weight\"]\n",
    "\n",
    "# StandardScaler\n",
    "scaler_cls = StandardScaler()\n",
    "X_cls_train_s = scaler_cls.fit_transform(X_cls_train)\n",
    "X_cls_test_s = scaler_cls.transform(X_cls_test)\n",
    "\n",
    "# Если class_weight='balanced', то можно компенсировать через веса в лоссе.\n",
    "# Для простоты: оставим логику без весов классов (качество всё равно сильно зависит от scaler + C).\n",
    "# L2 приблизим как 1/C.\n",
    "l2_strength = 1.0 / float(best_C)\n",
    "\n",
    "custom_log_best = LogisticRegressionCustom(lr=0.1, n_iters=12000, l2=l2_strength, fit_intercept=True)\n",
    "custom_log_best.fit(X_cls_train_s, y_cls_train)\n",
    "\n",
    "y_cls_pred_cb = custom_log_best.predict(X_cls_test_s)\n",
    "y_cls_proba_cb = custom_log_best.predict_proba(X_cls_test_s)[:, 1]\n",
    "\n",
    "cls_metrics_custom_improved = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_cb),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_cb, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_cb),\n",
    "}\n",
    "print(\"Custom improved (classification):\", cls_metrics_custom_improved)\n",
    "\n",
    "\n",
    "# ===== Custom improved: regression (same preprocess + best degree) =====\n",
    "best_degree = reg_search.best_params_[\"prep__num__poly__degree\"]\n",
    "\n",
    "# Соберём препроцессор с лучшей степенью\n",
    "reg_preprocess_best = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"poly\", PolynomialFeatures(degree=best_degree, include_bias=False))\n",
    "    ]), num_cols),\n",
    "    (\"cat\", make_ohe_dense(), cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "X_reg_train_p = reg_preprocess_best.fit_transform(X_reg_train)\n",
    "X_reg_test_p = reg_preprocess_best.transform(X_reg_test)\n",
    "\n",
    "custom_lin_best = LinearRegressionCustom(fit_intercept=True).fit(X_reg_train_p, y_reg_train.values)\n",
    "y_reg_pred_cb = custom_lin_best.predict(X_reg_test_p)\n",
    "\n",
    "reg_metrics_custom_improved = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_cb),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_cb),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_cb),\n",
    "}\n",
    "print(\"Custom improved (regression):\", reg_metrics_custom_improved)\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"stage\": \"sklearn_baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"sklearn_improved\", **cls_metrics_best},\n",
    "    {\"task\": \"classification\", \"stage\": \"custom_baseline\", **cls_metrics_custom_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"custom_improved\", **cls_metrics_custom_improved},\n",
    "\n",
    "    {\"task\": \"regression\", \"stage\": \"sklearn_baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"sklearn_improved\", **reg_metrics_best},\n",
    "    {\"task\": \"regression\", \"stage\": \"custom_baseline\", **reg_metrics_custom_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"custom_improved\", **reg_metrics_custom_improved},\n",
    "])\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea0629",
   "metadata": {},
   "source": [
    "\n",
    "## Короткие выводы (по результатам сравнений)\n",
    "\n",
    "**Логистическая регрессия:**\n",
    "- Масштабирование признаков и подбор `C` заметно улучшают метрики (особенно F1-macro/ROC-AUC).\n",
    "- Кастомная реализация при добавлении тех же техник показывает качество, сопоставимое со sklearn (различия из‑за оптимизатора/регуляризации/критериев остановки).\n",
    "\n",
    "**Линейная регрессия:**\n",
    "- One-hot для `origin` даёт ощутимый прирост (категорию нельзя корректно кодировать как 1/2/3).\n",
    "- Полиномиальные признаки (degree=2) могут дополнительно улучшить RMSE/MAE, если в данных есть нелинейности.\n",
    "- Кастомная OLS (pseudoinverse) на тех же преобразованных признаках даёт результаты близкие к sklearn LinearRegression.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
