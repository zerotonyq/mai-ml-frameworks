{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97b540e",
   "metadata": {},
   "source": [
    "\n",
    "# Лабораторная работа №3 - исследования с решающим деревом  \n",
    "(повтор пунктов 2–4 из ЛР №1)\n",
    "\n",
    "В ноутбуке выполнены пункты **2–4**:\n",
    "- **2. Создание бейзлайна и оценка качества** (sklearn)\n",
    "- **3. Улучшение бейзлайна** (гипотезы → проверка → улучшенный бейзлайн)\n",
    "- **4. Имплементация алгоритма** (Decision Tree) **с нуля** + сравнения\n",
    "\n",
    "## Открытые датасеты по ссылке (UCI)\n",
    "- **Классификация:** Banknote Authentication  \n",
    "  `https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt`\n",
    "- **Регрессия:** Auto MPG  \n",
    "  `https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data`\n",
    "\n",
    "## Метрики\n",
    "- Классификация: **accuracy**, **F1-macro**, **ROC-AUC**\n",
    "- Регрессия: **MAE**, **RMSE**, **R²**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66a1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Literal\n",
    "import inspect\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# Версия-агностичный OneHotEncoder (чтобы не ловить ошибки из-за sparse/sparse_output)\n",
    "def make_ohe_dense():\n",
    "    sig = inspect.signature(OneHotEncoder)\n",
    "    if \"sparse_output\" in sig.parameters:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2faca00",
   "metadata": {},
   "source": [
    "## Загрузка данных (по ссылке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4abc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zerotonyq\\AppData\\Local\\Temp\\ipykernel_25296\\959624252.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_reg = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model_year  origin                   car_name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banknote shape: (1372, 5)\n",
      "Auto MPG shape: (398, 9)\n",
      "\n",
      "Missing (Auto MPG):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_year</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car_name</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              missing\n",
       "mpg                 0\n",
       "cylinders           0\n",
       "displacement        0\n",
       "horsepower          6\n",
       "weight              0\n",
       "acceleration        0\n",
       "model_year          0\n",
       "origin              0\n",
       "car_name            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Banknote Authentication (classification) =====\n",
    "banknote_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
    "banknote_cols = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
    "df_cls = pd.read_csv(banknote_url, header=None, names=banknote_cols)\n",
    "\n",
    "# ===== Auto MPG (regression) =====\n",
    "auto_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "auto_cols = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\", \"car_name\"]\n",
    "df_reg = pd.read_csv(\n",
    "    auto_url,\n",
    "    delim_whitespace=True,\n",
    "    header=None,\n",
    "    names=auto_cols,\n",
    "    na_values=\"?\"\n",
    ")\n",
    "\n",
    "display(df_cls.head())\n",
    "display(df_reg.head())\n",
    "\n",
    "print(\"Banknote shape:\", df_cls.shape)\n",
    "print(\"Auto MPG shape:\", df_reg.shape)\n",
    "print(\"\\nMissing (Auto MPG):\")\n",
    "display(df_reg.isna().sum().to_frame(\"missing\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f7a93",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Создание бейзлайна и оценка качества (sklearn)\n",
    "\n",
    "### 2.1 Разбиение train/test\n",
    "- Классификация: `stratify` по классам.\n",
    "- Регрессия: обычное разбиение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b54aed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls train/test: (1097, 4) (275, 4)\n",
      "reg train/test: (318, 7) (80, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Classification =====\n",
    "X_cls = df_cls.drop(columns=[\"class\"]).values\n",
    "y_cls = df_cls[\"class\"].values\n",
    "\n",
    "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(\n",
    "    X_cls, y_cls,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_cls\n",
    ")\n",
    "\n",
    "# ===== Regression =====\n",
    "# car_name убираем (строковый признак)\n",
    "df_reg_base = df_reg.drop(columns=[\"car_name\"]).copy()\n",
    "X_reg = df_reg_base.drop(columns=[\"mpg\"])\n",
    "y_reg = df_reg_base[\"mpg\"]\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"cls train/test:\", X_cls_train.shape, X_cls_test.shape)\n",
    "print(\"reg train/test:\", X_reg_train.shape, X_reg_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cac66d",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Бейзлайн: DecisionTreeClassifier и DecisionTreeRegressor\n",
    "\n",
    "- Для классификации дереву **не нужно** масштабирование.\n",
    "- Для регрессии обязательно обработать пропуски (`horsepower` = '?') → импутация медианой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c05cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (classification): {'accuracy': 0.9927272727272727, 'f1_macro': 0.992645485665383, 'roc_auc': 0.9934640522875817}\n",
      "Baseline (regression): {'mae': 2.2225, 'rmse': 3.3371769506575464, 'r2': 0.7928680190978783}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Baseline: Classification =====\n",
    "dtc_base = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "dtc_base.fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred = dtc_base.predict(X_cls_test)\n",
    "y_cls_proba = dtc_base.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_base = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba),\n",
    "}\n",
    "print(\"Baseline (classification):\", cls_metrics_base)\n",
    "\n",
    "# ===== Baseline: Regression (simple imputation, origin as numeric) =====\n",
    "dtr_base = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=RANDOM_STATE)),\n",
    "])\n",
    "dtr_base.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred = dtr_base.predict(X_reg_test)\n",
    "\n",
    "reg_metrics_base = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred),\n",
    "}\n",
    "print(\"Baseline (regression):\", reg_metrics_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899adca0",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Улучшение бейзлайна\n",
    "\n",
    "### 3.1 Гипотезы улучшения\n",
    "\n",
    "**Классификация:**\n",
    "1. Подбор гиперпараметров предобрезки (`max_depth`, `min_samples_split`, `min_samples_leaf`) уменьшит переобучение и улучшит качество на тесте.\n",
    "2. Смена критерия разбиения (`gini` / `entropy`) может дать прирост.\n",
    "\n",
    "**Регрессия:**\n",
    "1. Импутация остаётся обязательной.\n",
    "2. `origin` лучше обрабатывать как **категориальный** признак → one-hot.\n",
    "3. Подбор `max_depth`, `min_samples_leaf`, `min_samples_split` уменьшит переобучение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f324235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (classification): {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "CV best f1_macro: 0.9917111496228085\n",
      "Improved (classification): {'accuracy': 0.9927272727272727, 'f1_macro': 0.992645485665383, 'roc_auc': 0.9934640522875817}\n",
      "Best params (regression): {'model__criterion': 'squared_error', 'model__max_depth': 5, 'model__min_samples_leaf': 10, 'model__min_samples_split': 2}\n",
      "CV best (neg RMSE): -3.3909546777838755\n",
      "Improved (regression): {'mae': 1.9866984376910846, 'rmse': 2.7235988230803807, 'r2': 0.862033081756782}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>improved</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.222500</td>\n",
       "      <td>3.337177</td>\n",
       "      <td>0.792868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.986698</td>\n",
       "      <td>2.723599</td>\n",
       "      <td>0.862033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task     stage  accuracy  f1_macro   roc_auc       mae      rmse  \\\n",
       "0  classification  baseline  0.992727  0.992645  0.993464       NaN       NaN   \n",
       "1  classification  improved  0.992727  0.992645  0.993464       NaN       NaN   \n",
       "2      regression  baseline       NaN       NaN       NaN  2.222500  3.337177   \n",
       "3      regression  improved       NaN       NaN       NaN  1.986698  2.723599   \n",
       "\n",
       "         r2  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2  0.792868  \n",
       "3  0.862033  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Improved: Classification (GridSearchCV) =====\n",
    "cls_param_grid = {\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 7, 10],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "cv_cls = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cls_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    cls_param_grid,\n",
    "    cv=cv_cls,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "cls_search.fit(X_cls_train, y_cls_train)\n",
    "\n",
    "print(\"Best params (classification):\", cls_search.best_params_)\n",
    "print(\"CV best f1_macro:\", cls_search.best_score_)\n",
    "\n",
    "dtc_best = cls_search.best_estimator_\n",
    "y_cls_pred_best = dtc_best.predict(X_cls_test)\n",
    "y_cls_proba_best = dtc_best.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_best = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_best),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_best, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_best),\n",
    "}\n",
    "print(\"Improved (classification):\", cls_metrics_best)\n",
    "\n",
    "\n",
    "# ===== Improved: Regression (one-hot origin + GridSearchCV) =====\n",
    "num_cols = [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\"]\n",
    "cat_cols = [\"origin\"]\n",
    "\n",
    "reg_preprocess = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", make_ohe_dense(), cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    (\"prep\", reg_preprocess),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=RANDOM_STATE)),\n",
    "])\n",
    "\n",
    "reg_param_grid = {\n",
    "    \"model__max_depth\": [None, 2, 3, 4, 5, 7, 10, 15],\n",
    "    \"model__min_samples_split\": [2, 5, 10, 20],\n",
    "    \"model__min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"model__criterion\": [\"squared_error\"],  # оставляем совместимое с кастомной реализацией\n",
    "}\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "reg_search = GridSearchCV(\n",
    "    reg_pipe,\n",
    "    reg_param_grid,\n",
    "    cv=cv_reg,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "reg_search.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "print(\"Best params (regression):\", reg_search.best_params_)\n",
    "print(\"CV best (neg RMSE):\", reg_search.best_score_)\n",
    "\n",
    "dtr_best = reg_search.best_estimator_\n",
    "y_reg_pred_best = dtr_best.predict(X_reg_test)\n",
    "\n",
    "reg_metrics_best = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_best),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_best),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_best),\n",
    "}\n",
    "print(\"Improved (regression):\", reg_metrics_best)\n",
    "\n",
    "compare = pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"stage\": \"baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"improved\", **cls_metrics_best},\n",
    "    {\"task\": \"regression\", \"stage\": \"baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"improved\", **reg_metrics_best},\n",
    "])\n",
    "display(compare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01396087",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Имплементация решающего дерева (с нуля)\n",
    "\n",
    "Ниже - компактная реализация бинарного дерева:\n",
    "- **Классификация:** критерий `gini` или `entropy`\n",
    "- **Регрессия:** критерий `mse` (squared error)\n",
    "\n",
    "Для скорости поиск лучшего сплита делается через сортировку и префиксные суммы (быстрее, чем перебор масками).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cbe8bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _gini(counts: np.ndarray) -> float:\n",
    "    # counts: (n_classes,)\n",
    "    total = counts.sum()\n",
    "    if total <= 0:\n",
    "        return 0.0\n",
    "    p = counts / total\n",
    "    return float(1.0 - np.sum(p ** 2))\n",
    "\n",
    "def _entropy(counts: np.ndarray) -> float:\n",
    "    total = counts.sum()\n",
    "    if total <= 0:\n",
    "        return 0.0\n",
    "    p = counts / total\n",
    "    p = p[p > 0]\n",
    "    return float(-np.sum(p * np.log2(p)))\n",
    "\n",
    "def _mse_from_sums(sum_y: float, sum_y2: float, n: int) -> float:\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    mean = sum_y / n\n",
    "    # E[y^2] - (E[y])^2\n",
    "    return float(sum_y2 / n - mean * mean)\n",
    "\n",
    "@dataclass\n",
    "class _Node:\n",
    "    feature: Optional[int] = None\n",
    "    threshold: Optional[float] = None\n",
    "    left: Optional[\"__class__\"] = None\n",
    "    right: Optional[\"__class__\"] = None\n",
    "    value: Optional[float] = None  # регрессия: mean; классификация: класс (int)\n",
    "\n",
    "class DecisionTreeClassifierCustom:\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: int = 2,\n",
    "                 min_samples_leaf: int = 1,\n",
    "                 criterion: Literal[\"gini\", \"entropy\"] = \"gini\"):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = int(min_samples_split)\n",
    "        self.min_samples_leaf = int(min_samples_leaf)\n",
    "        self.criterion = criterion\n",
    "        self.root_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=int)\n",
    "        self.classes_, y_enc = np.unique(y, return_inverse=True)\n",
    "        self.root_ = self._build(X, y_enc, depth=0)\n",
    "        return self\n",
    "\n",
    "    def _impurity(self, counts):\n",
    "        return _gini(counts) if self.criterion == \"gini\" else _entropy(counts)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        n, d = X.shape\n",
    "        n_classes = int(y.max() + 1)\n",
    "\n",
    "        # текущая impurity\n",
    "        total_counts = np.bincount(y, minlength=n_classes).astype(float)\n",
    "        best_imp = float(\"inf\")\n",
    "        best_f = None\n",
    "        best_thr = None\n",
    "\n",
    "        for f in range(d):\n",
    "            xs = X[:, f]\n",
    "            order = np.argsort(xs, kind=\"mergesort\")\n",
    "            xs_sorted = xs[order]\n",
    "            y_sorted = y[order]\n",
    "\n",
    "            # кандидаты сплитов только там, где значение меняется\n",
    "            diffs = xs_sorted[1:] != xs_sorted[:-1]\n",
    "            if not np.any(diffs):\n",
    "                continue\n",
    "\n",
    "            # префиксные суммы по классам\n",
    "            left_counts = np.zeros((n - 1, n_classes), dtype=float)\n",
    "            running = np.zeros(n_classes, dtype=float)\n",
    "            for i in range(n - 1):\n",
    "                running[y_sorted[i]] += 1.0\n",
    "                left_counts[i] = running\n",
    "\n",
    "            right_counts = total_counts - left_counts\n",
    "\n",
    "            # ограничения на min_samples_leaf\n",
    "            left_n = np.arange(1, n)\n",
    "            right_n = n - left_n\n",
    "            valid = diffs & (left_n >= self.min_samples_leaf) & (right_n >= self.min_samples_leaf)\n",
    "            if not np.any(valid):\n",
    "                continue\n",
    "\n",
    "            # impurity для каждого i (сплит между i и i+1)\n",
    "            imp_left = np.array([self._impurity(c) for c in left_counts])\n",
    "            imp_right = np.array([self._impurity(c) for c in right_counts])\n",
    "            weighted = (left_n * imp_left + right_n * imp_right) / n\n",
    "\n",
    "            # выбираем лучший valid\n",
    "            weighted[~valid] = np.inf\n",
    "            i_best = int(np.argmin(weighted))\n",
    "            if weighted[i_best] < best_imp:\n",
    "                best_imp = float(weighted[i_best])\n",
    "                best_f = f\n",
    "                best_thr = float((xs_sorted[i_best] + xs_sorted[i_best + 1]) / 2.0)\n",
    "\n",
    "        return best_f, best_thr\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        # most frequent class\n",
    "        counts = np.bincount(y)\n",
    "        return int(np.argmax(counts))\n",
    "\n",
    "    def _build(self, X, y, depth):\n",
    "        n = X.shape[0]\n",
    "\n",
    "        # stopping\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or            (n < self.min_samples_split) or            (len(np.unique(y)) == 1):\n",
    "            return _Node(value=self._leaf_value(y))\n",
    "\n",
    "        f, thr = self._best_split(X, y)\n",
    "        if f is None:\n",
    "            return _Node(value=self._leaf_value(y))\n",
    "\n",
    "        left_mask = X[:, f] <= thr\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
    "            return _Node(value=self._leaf_value(y))\n",
    "\n",
    "        node = _Node(feature=f, threshold=thr)\n",
    "        node.left = self._build(X[left_mask], y[left_mask], depth + 1)\n",
    "        node.right = self._build(X[right_mask], y[right_mask], depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict_one(self, x, node: _Node):\n",
    "        while node.feature is not None:\n",
    "            node = node.left if x[node.feature] <= node.threshold else node.right\n",
    "        return node.value\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        preds_enc = np.array([self._predict_one(x, self.root_) for x in X], dtype=int)\n",
    "        return self.classes_[preds_enc]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # простая proba: доля класса-1 в листе не храним,\n",
    "        # поэтому вернём 0/1 как \"жёсткую\" вероятность (для ROC-AUC ок как baseline).\n",
    "        # Для более точного proba можно хранить распределение классов в листьях.\n",
    "        y_hat = self.predict(X)\n",
    "        # бинарный случай 0/1\n",
    "        proba_1 = (y_hat == 1).astype(float)\n",
    "        return np.vstack([1 - proba_1, proba_1]).T\n",
    "\n",
    "\n",
    "class DecisionTreeRegressorCustom:\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: int = 2,\n",
    "                 min_samples_leaf: int = 1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = int(min_samples_split)\n",
    "        self.min_samples_leaf = int(min_samples_leaf)\n",
    "        self.root_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        self.root_ = self._build(X, y, depth=0)\n",
    "        return self\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        n, d = X.shape\n",
    "        best_loss = float(\"inf\")\n",
    "        best_f = None\n",
    "        best_thr = None\n",
    "\n",
    "        total_sum = float(np.sum(y))\n",
    "        total_sum2 = float(np.sum(y ** 2))\n",
    "\n",
    "        for f in range(d):\n",
    "            xs = X[:, f]\n",
    "            order = np.argsort(xs, kind=\"mergesort\")\n",
    "            xs_sorted = xs[order]\n",
    "            y_sorted = y[order]\n",
    "\n",
    "            diffs = xs_sorted[1:] != xs_sorted[:-1]\n",
    "            if not np.any(diffs):\n",
    "                continue\n",
    "\n",
    "            # префиксные суммы y и y^2\n",
    "            prefix_sum = np.cumsum(y_sorted[:-1])\n",
    "            prefix_sum2 = np.cumsum((y_sorted[:-1]) ** 2)\n",
    "\n",
    "            left_n = np.arange(1, n)\n",
    "            right_n = n - left_n\n",
    "\n",
    "            right_sum = total_sum - prefix_sum\n",
    "            right_sum2 = total_sum2 - prefix_sum2\n",
    "\n",
    "            valid = diffs & (left_n >= self.min_samples_leaf) & (right_n >= self.min_samples_leaf)\n",
    "            if not np.any(valid):\n",
    "                continue\n",
    "\n",
    "            left_mse = np.array([_mse_from_sums(prefix_sum[i], prefix_sum2[i], int(left_n[i])) for i in range(n - 1)])\n",
    "            right_mse = np.array([_mse_from_sums(right_sum[i], right_sum2[i], int(right_n[i])) for i in range(n - 1)])\n",
    "            weighted = (left_n * left_mse + right_n * right_mse) / n\n",
    "\n",
    "            weighted[~valid] = np.inf\n",
    "            i_best = int(np.argmin(weighted))\n",
    "            if weighted[i_best] < best_loss:\n",
    "                best_loss = float(weighted[i_best])\n",
    "                best_f = f\n",
    "                best_thr = float((xs_sorted[i_best] + xs_sorted[i_best + 1]) / 2.0)\n",
    "\n",
    "        return best_f, best_thr\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        return float(np.mean(y)) if y.size else 0.0\n",
    "\n",
    "    def _build(self, X, y, depth):\n",
    "        n = X.shape[0]\n",
    "\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or            (n < self.min_samples_split) or            (n <= 2 * self.min_samples_leaf):\n",
    "            return _Node(value=self._leaf_value(y))\n",
    "\n",
    "        f, thr = self._best_split(X, y)\n",
    "        if f is None:\n",
    "            return _Node(value=self._leaf_value(y))\n",
    "\n",
    "        left_mask = X[:, f] <= thr\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
    "            return _Node(value=self._leaf_value(y))\n",
    "\n",
    "        node = _Node(feature=f, threshold=thr)\n",
    "        node.left = self._build(X[left_mask], y[left_mask], depth + 1)\n",
    "        node.right = self._build(X[right_mask], y[right_mask], depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict_one(self, x, node: _Node):\n",
    "        while node.feature is not None:\n",
    "            node = node.left if x[node.feature] <= node.threshold else node.right\n",
    "        return node.value\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return np.array([self._predict_one(x, self.root_) for x in X], dtype=float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12b27a",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Кастомные модели vs бейзлайн (пункт 2)\n",
    "\n",
    "Для честного сравнения:\n",
    "- **Классификация:** сырые признаки (как в п.2).\n",
    "- **Регрессия:** медианная импутация для числовых признаков (как в п.2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac72470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom baseline (classification): {'accuracy': 0.9927272727272727, 'f1_macro': 0.992645485665383, 'roc_auc': 0.9934640522875817}\n",
      "Custom baseline (regression): {'mae': 2.25625, 'rmse': 3.379497003993346, 'r2': 0.7875812643829545}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.22250</td>\n",
       "      <td>3.337177</td>\n",
       "      <td>0.792868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.25625</td>\n",
       "      <td>3.379497</td>\n",
       "      <td>0.787581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task             model  accuracy  f1_macro   roc_auc      mae  \\\n",
       "0  classification  sklearn_baseline  0.992727  0.992645  0.993464      NaN   \n",
       "1  classification   custom_baseline  0.992727  0.992645  0.993464      NaN   \n",
       "2      regression  sklearn_baseline       NaN       NaN       NaN  2.22250   \n",
       "3      regression   custom_baseline       NaN       NaN       NaN  2.25625   \n",
       "\n",
       "       rmse        r2  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2  3.337177  0.792868  \n",
       "3  3.379497  0.787581  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Custom baseline: classification =====\n",
    "custom_dtc = DecisionTreeClassifierCustom(\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    criterion=\"gini\"\n",
    ").fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred_c = custom_dtc.predict(X_cls_test)\n",
    "y_cls_proba_c = custom_dtc.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_custom_base = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_c),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_c, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_c),\n",
    "}\n",
    "print(\"Custom baseline (classification):\", cls_metrics_custom_base)\n",
    "\n",
    "# ===== Custom baseline: regression =====\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "Xr_train_imp = imp.fit_transform(X_reg_train)\n",
    "Xr_test_imp = imp.transform(X_reg_test)\n",
    "\n",
    "custom_dtr = DecisionTreeRegressorCustom(\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1\n",
    ").fit(Xr_train_imp, y_reg_train.values)\n",
    "\n",
    "y_reg_pred_c = custom_dtr.predict(Xr_test_imp)\n",
    "\n",
    "reg_metrics_custom_base = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_c),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_c),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_c),\n",
    "}\n",
    "print(\"Custom baseline (regression):\", reg_metrics_custom_base)\n",
    "\n",
    "display(pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"model\": \"sklearn_baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"model\": \"custom_baseline\", **cls_metrics_custom_base},\n",
    "    {\"task\": \"regression\", \"model\": \"sklearn_baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"model\": \"custom_baseline\", **reg_metrics_custom_base},\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92469e66",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Добавляем техники улучшенного бейзлайна (пункт 3) к кастомным моделям\n",
    "\n",
    "Берём лучшие гиперпараметры из GridSearchCV и применяем те же преобразования:\n",
    "- Классификация: лучшие `max_depth/min_samples_*` и критерий.\n",
    "- Регрессия: one-hot(origin) + импутация + лучшие `max_depth/min_samples_*`.\n",
    "\n",
    "> Примечание: у кастомного дерева `predict_proba` сделано упрощённо (жёсткая 0/1), поэтому ROC-AUC может быть ниже, чем у sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360ddb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom improved (classification): {'accuracy': 0.9927272727272727, 'f1_macro': 0.992645485665383, 'roc_auc': 0.9934640522875817}\n",
      "Custom improved (regression): {'mae': 2.0115734376910845, 'rmse': 2.7627362883715176, 'r2': 0.858039489563882}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_improved</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_improved</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.992645</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.222500</td>\n",
       "      <td>3.337177</td>\n",
       "      <td>0.792868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.986698</td>\n",
       "      <td>2.723599</td>\n",
       "      <td>0.862033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.256250</td>\n",
       "      <td>3.379497</td>\n",
       "      <td>0.787581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.011573</td>\n",
       "      <td>2.762736</td>\n",
       "      <td>0.858039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task             stage  accuracy  f1_macro   roc_auc       mae  \\\n",
       "0  classification  sklearn_baseline  0.992727  0.992645  0.993464       NaN   \n",
       "1  classification  sklearn_improved  0.992727  0.992645  0.993464       NaN   \n",
       "2  classification   custom_baseline  0.992727  0.992645  0.993464       NaN   \n",
       "3  classification   custom_improved  0.992727  0.992645  0.993464       NaN   \n",
       "4      regression  sklearn_baseline       NaN       NaN       NaN  2.222500   \n",
       "5      regression  sklearn_improved       NaN       NaN       NaN  1.986698   \n",
       "6      regression   custom_baseline       NaN       NaN       NaN  2.256250   \n",
       "7      regression   custom_improved       NaN       NaN       NaN  2.011573   \n",
       "\n",
       "       rmse        r2  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4  3.337177  0.792868  \n",
       "5  2.723599  0.862033  \n",
       "6  3.379497  0.787581  \n",
       "7  2.762736  0.858039  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Custom improved: classification (best params) =====\n",
    "bp = cls_search.best_params_\n",
    "custom_dtc_best = DecisionTreeClassifierCustom(\n",
    "    max_depth=bp[\"max_depth\"],\n",
    "    min_samples_split=bp[\"min_samples_split\"],\n",
    "    min_samples_leaf=bp[\"min_samples_leaf\"],\n",
    "    criterion=bp[\"criterion\"]\n",
    ").fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred_cb = custom_dtc_best.predict(X_cls_test)\n",
    "y_cls_proba_cb = custom_dtc_best.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_custom_improved = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_cb),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_cb, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_cb),\n",
    "}\n",
    "print(\"Custom improved (classification):\", cls_metrics_custom_improved)\n",
    "\n",
    "\n",
    "# ===== Custom improved: regression (same preprocess + best params) =====\n",
    "bp_r = reg_search.best_params_\n",
    "max_depth = bp_r[\"model__max_depth\"]\n",
    "min_split = bp_r[\"model__min_samples_split\"]\n",
    "min_leaf = bp_r[\"model__min_samples_leaf\"]\n",
    "\n",
    "# Преобразуем признаки так же, как в улучшенном пайплайне\n",
    "X_reg_train_p = reg_preprocess.fit_transform(X_reg_train)\n",
    "X_reg_test_p = reg_preprocess.transform(X_reg_test)\n",
    "\n",
    "custom_dtr_best = DecisionTreeRegressorCustom(\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_split,\n",
    "    min_samples_leaf=min_leaf\n",
    ").fit(X_reg_train_p, y_reg_train.values)\n",
    "\n",
    "y_reg_pred_cb = custom_dtr_best.predict(X_reg_test_p)\n",
    "\n",
    "reg_metrics_custom_improved = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_cb),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_cb),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_cb),\n",
    "}\n",
    "print(\"Custom improved (regression):\", reg_metrics_custom_improved)\n",
    "\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"stage\": \"sklearn_baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"sklearn_improved\", **cls_metrics_best},\n",
    "    {\"task\": \"classification\", \"stage\": \"custom_baseline\", **cls_metrics_custom_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"custom_improved\", **cls_metrics_custom_improved},\n",
    "\n",
    "    {\"task\": \"regression\", \"stage\": \"sklearn_baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"sklearn_improved\", **reg_metrics_best},\n",
    "    {\"task\": \"regression\", \"stage\": \"custom_baseline\", **reg_metrics_custom_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"custom_improved\", **reg_metrics_custom_improved},\n",
    "])\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11849e66",
   "metadata": {},
   "source": [
    "\n",
    "## Выводы (кратко по пунктам)\n",
    "\n",
    "**Классификация:**\n",
    "1. Бейзлайн-дерево часто переобучается (глубокое дерево запоминает обучающую выборку).\n",
    "2. Подбор `max_depth/min_samples_leaf/min_samples_split` обычно улучшает качество на тесте.\n",
    "3. Выбор критерия (`gini`/`entropy`) иногда даёт небольшой прирост.\n",
    "4. Кастомная реализация воспроизводит идею CART и даёт качество близкое к sklearn при тех же ограничениях дерева (различия из-за деталей реализации и вероятностей).\n",
    "\n",
    "**Регрессия:**\n",
    "1. Без ограничений глубины дерево легко переобучается → высокие ошибки на тесте.\n",
    "2. Импутация обязательна из-за пропусков в `horsepower`.\n",
    "3. One-hot для `origin` улучшает качество (категория не должна быть числом 1/2/3 в смысле “больше/меньше”).\n",
    "4. Подбор предобрезки даёт стабильный прирост (снижение RMSE/MAE, рост R²).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
