
# README - Лабораторные работы

> **ФИО:** Гиголаев Антон Александрович 
> **Группа:** М8О-409Б-22  
> **Дисциплина:** Прикладные системы и фреймворки искусственного интеллекта  

## 1. Состав работы (что сделано)



### Файлы (ноутбуки)

- `LR1.ipynb` - KNN (классификация + регрессия)
- `LR2.ipynb` - логистическая регрессия (классификация) + линейная регрессия (регрессия)
- `LR3.ipynb` - решающее дерево (классификация + регрессия)
- `LR4.ipynb` - случайный лес (классификация + регрессия)
- `LR5.ipynb` - градиентный бустинг (классификация + регрессия) + итоговые сравнения по ЛР 1–5

## 2. Выбор задач и датасетов

Во всех работах использованы **открытые датасеты из UCI Machine Learning Repository**, доступные по прямым ссылкам (загрузка в ноутбуках происходит через `pandas.read_csv(url)`).

### 2.1 Классификация: Banknote Authentication (UCI)

**Ссылка:**  
`https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt`

**Суть практической задачи:**  
Определение поддельной/настоящей банкноты по набору числовых признаков (полученных из изображений банкнот). Это реальная прикладная задача бинарной классификации.

**Признаки:** `variance`, `skewness`, `curtosis`, `entropy`  
**Целевая переменная:** `class` (0/1)

### 2.2 Регрессия: Auto MPG (UCI)

**Ссылка:**  
`https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data`

**Суть практической задачи:**  
Прогноз расхода топлива автомобиля (mpg) по техническим характеристикам. Это реальная прикладная задача регрессии (оценка эксплуатационного параметра по признакам автомобиля).

**Признаки:** `cylinders`, `displacement`, `horsepower`, `weight`, `acceleration`, `model_year`, `origin`  
**Целевая переменная:** `mpg`  
**Особенности данных:**  
- `horsepower` содержит пропуски, обозначенные `?` → требуется обработка пропусков  
- `origin` - категориальный признак (значения 1/2/3), корректнее кодировать через one-hot

## 3. Метрики качества и обоснование

### 3.1 Для классификации
Использовались метрики:
- **Accuracy** - доля верных ответов, простая базовая метрика
- **F1-macro** - усреднённая F1 по классам; полезна, когда важна устойчивость к дисбалансу и качество по каждому классу
- **ROC-AUC** - качество ранжирования по вероятностям; показывает, насколько модель разделяет классы по score

### 3.2 Для регрессии
Использовались метрики:
- **MAE** - средняя абсолютная ошибка (интерпретируется в единицах целевой переменной)
- **RMSE** - корень из MSE; сильнее штрафует большие ошибки
- **R²** - доля объяснённой дисперсии (насколько модель лучше константного предсказания)

## 4. Общая схема экспериментов (как проводилось)

Во всех ноутбуках эксперименты построены одинаково:

1) **Разделение данных на train/test**
- Классификация: `train_test_split(..., stratify=y)`
- Регрессия: обычное `train_test_split(...)`

2) **Бейзлайн (пункт 2)**
- Обучение модели из `sklearn`
- Оценка качества на test по выбранным метрикам

3) **Улучшение (пункт 3)**
- Формулировка гипотез (препроцессинг, гиперпараметры, CV)
- Проверка гипотез через `GridSearchCV`
- Получение **улучшенного бейзлайна** и оценка на test.
- Сравнение baseline vs improved

4) **Имплементация (пункт 4)**
- Реализация алгоритма **с нуля** (NumPy/Python)
- Обучение на train
- Оценка на test
- Сравнение:
  - кастомная модель vs sklearn baseline (из п.2)
  - кастомная модель + техники улучшенного бейзлайна vs improved (из п.3)

## 5. Препроцессинг и важные детали

### 5.1 Banknote Authentication
- Данные уже числовые, пропусков нет
- Для KNN/логистической регрессии использовался `StandardScaler` (в improved вариантах), т.к. алгоритмы чувствительны к масштабу

### 5.2 Auto MPG
- Удалялся строковый столбец `car_name`
- `horsepower` имеет пропуски `?` → использовалась импутация медианой: `SimpleImputer(strategy="median")`
- `origin` трактовался как категориальный признак → `OneHotEncoder(handle_unknown="ignore")`
- Для моделей, где это уместно (например, в ЛР2), применялись дополнительные преобразования (например, полиномиальные признаки для числовых столбцов).

## 6. Что именно сделано по каждой лабораторной

### ЛР1 - KNN
- `KNeighborsClassifier`, `KNeighborsRegressor` (baseline)
- Улучшение: `StandardScaler`, подбор `n_neighbors`, `weights`, `p` через `GridSearchCV`
- Имплементация: KNN  (поиск соседей, расстояния, голосование/среднее)

### ЛР2 - логистическая и линейная регрессия
- baseline: `LogisticRegression`, `LinearRegression`
- улучшение: scaler + подбор `C`, `class_weight` для логистической; для регрессии - корректный препроцессинг, опционально полиномиальные признаки
- имплементация:
  - логистическая регрессия: градиентный спуск
  - линейная регрессия: решение через псевдообратную матрицу

### ЛР3 - решающее дерево
- baseline: `DecisionTreeClassifier`, `DecisionTreeRegressor`
- улучшение: подбор `max_depth`, `min_samples_split`, `min_samples_leaf`, `criterion`
- имплементация: дерево (поиск лучшего разбиения, рекурсивное построение, предсказание)

### ЛР4 - случайный лес
- baseline: `RandomForestClassifier`, `RandomForestRegressor`
- улучшение: подбор ключевых параметров (`n_estimators`, `max_depth`, `min_samples_*`, `max_features`, `bootstrap`)
- имплементация: Random Forest  (bagging + случайный поднабор признаков в узлах, усреднение/голосование)

### ЛР5 - градиентный бустинг + итоговое сравнение
- baseline: `GradientBoostingClassifier`, `GradientBoostingRegressor`
- улучшение: `GridSearchCV` по `n_estimators`, `learning_rate`, `max_depth`, `subsample`
- имплементация: Gradient Boostingg  в упрощённом виде (stumps + обновление по остаткам)
- **Итоги:** автоматическая таблица сравнения всех моделей ЛР1–ЛР5 на test:
  - классификация: сравнение по F1-macro (+ дополнительные метрики)
  - регрессия: сравнение по RMSE (+ дополнительные метрики)
  - построены графики по baseline/improved

## 7. Используемые библиотеки и окружение

Рекомендуемое окружение:
- Python 3.10+ (подойдёт и 3.9+)
- Основные библиотеки:
  - `numpy`
  - `pandas`
  - `scikit-learn`
  - `matplotlib`