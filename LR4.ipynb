{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0469d488",
   "metadata": {},
   "source": [
    "\n",
    "# Лабораторная работа №4 - исследования со случайным лесом (Random Forest)  \n",
    "(повтор пунктов 2–4 из ЛР №1)\n",
    "\n",
    "В ноутбуке выполнены пункты **2–4**:\n",
    "- **2. Создание бейзлайна и оценка качества** (sklearn)\n",
    "- **3. Улучшение бейзлайна** (гипотезы → проверка → улучшенный бейзлайн)\n",
    "- **4. Имплементация алгоритма** (Random Forest) **с нуля** + сравнения\n",
    "\n",
    "## Открытые датасеты по ссылке (UCI)\n",
    "- **Классификация:** Banknote Authentication  \n",
    "  `https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt`\n",
    "- **Регрессия:** Auto MPG  \n",
    "  `https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data`\n",
    "\n",
    "## Метрики\n",
    "- Классификация: **accuracy**, **F1-macro**, **ROC-AUC**\n",
    "- Регрессия: **MAE**, **RMSE**, **R²**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe33c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Literal\n",
    "import inspect\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# Версия-агностичный OneHotEncoder (чтобы не ловить ошибки из-за sparse/sparse_output)\n",
    "def make_ohe_dense():\n",
    "    sig = inspect.signature(OneHotEncoder)\n",
    "    if \"sparse_output\" in sig.parameters:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c925c8",
   "metadata": {},
   "source": [
    "## Загрузка данных (по ссылке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d53ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zerotonyq\\AppData\\Local\\Temp\\ipykernel_2424\\959624252.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_reg = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model_year  origin                   car_name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banknote shape: (1372, 5)\n",
      "Auto MPG shape: (398, 9)\n",
      "\n",
      "Missing (Auto MPG):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_year</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car_name</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              missing\n",
       "mpg                 0\n",
       "cylinders           0\n",
       "displacement        0\n",
       "horsepower          6\n",
       "weight              0\n",
       "acceleration        0\n",
       "model_year          0\n",
       "origin              0\n",
       "car_name            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Banknote Authentication (classification) =====\n",
    "banknote_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
    "banknote_cols = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
    "df_cls = pd.read_csv(banknote_url, header=None, names=banknote_cols)\n",
    "\n",
    "# ===== Auto MPG (regression) =====\n",
    "auto_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "auto_cols = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\", \"car_name\"]\n",
    "df_reg = pd.read_csv(\n",
    "    auto_url,\n",
    "    delim_whitespace=True,\n",
    "    header=None,\n",
    "    names=auto_cols,\n",
    "    na_values=\"?\"\n",
    ")\n",
    "\n",
    "display(df_cls.head())\n",
    "display(df_reg.head())\n",
    "\n",
    "print(\"Banknote shape:\", df_cls.shape)\n",
    "print(\"Auto MPG shape:\", df_reg.shape)\n",
    "print(\"\\nMissing (Auto MPG):\")\n",
    "display(df_reg.isna().sum().to_frame(\"missing\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c424d5f",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Создание бейзлайна и оценка качества (sklearn)\n",
    "\n",
    "### 2.1 Разбиение train/test\n",
    "- Классификация: `stratify` по классам.\n",
    "- Регрессия: обычное разбиение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cdfc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls train/test: (1097, 4) (275, 4)\n",
      "reg train/test: (318, 7) (80, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Classification =====\n",
    "X_cls = df_cls.drop(columns=[\"class\"]).values\n",
    "y_cls = df_cls[\"class\"].values\n",
    "\n",
    "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(\n",
    "    X_cls, y_cls,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_cls\n",
    ")\n",
    "\n",
    "# ===== Regression =====\n",
    "# car_name убираем (строковый признак)\n",
    "df_reg_base = df_reg.drop(columns=[\"car_name\"]).copy()\n",
    "X_reg = df_reg_base.drop(columns=[\"mpg\"])\n",
    "y_reg = df_reg_base[\"mpg\"]\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"cls train/test:\", X_cls_train.shape, X_cls_test.shape)\n",
    "print(\"reg train/test:\", X_reg_train.shape, X_reg_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df6cd7",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Бейзлайн: RandomForestClassifier и RandomForestRegressor\n",
    "\n",
    "Особенности Random Forest:\n",
    "- не требует масштабирования признаков;\n",
    "- устойчивее к переобучению, чем одно дерево, потому что усредняет много деревьев;\n",
    "- для регрессии всё равно нужно обработать пропуски (horsepower) и корректно обработать категориальный `origin`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f251b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (classification): {'accuracy': 0.9963636363636363, 'f1_macro': 0.9963198394111743, 'roc_auc': 1.0}\n",
      "Baseline (regression): {'mae': 1.5788458333333335, 'rmse': 2.1573822792011415, 'r2': 0.9134348866320341}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Baseline: Classification (RF) =====\n",
    "rfc_base = RandomForestClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_estimators=200,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfc_base.fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred = rfc_base.predict(X_cls_test)\n",
    "y_cls_proba = rfc_base.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_base = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba),\n",
    "}\n",
    "print(\"Baseline (classification):\", cls_metrics_base)\n",
    "\n",
    "# ===== Baseline: Regression (RF + preprocess) =====\n",
    "num_cols = [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\"]\n",
    "cat_cols = [\"origin\"]\n",
    "\n",
    "reg_preprocess_base = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", make_ohe_dense(), cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "rfr_base = Pipeline([\n",
    "    (\"prep\", reg_preprocess_base),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=300,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rfr_base.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred = rfr_base.predict(X_reg_test)\n",
    "\n",
    "reg_metrics_base = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred),\n",
    "}\n",
    "print(\"Baseline (regression):\", reg_metrics_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d48c0f",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Улучшение бейзлайна\n",
    "\n",
    "### 3.1 Гипотезы улучшения\n",
    "\n",
    "**Классификация (RandomForestClassifier):**\n",
    "1. Подбор `max_depth`, `min_samples_leaf`, `min_samples_split` уменьшит переобучение и улучшит качество на тесте.\n",
    "2. Подбор `max_features` влияет на разнообразие деревьев → может улучшить качество.\n",
    "3. Подбор `n_estimators` и `bootstrap` влияет на устойчивость и дисперсию.\n",
    "\n",
    "**Регрессия (RandomForestRegressor):**\n",
    "1. Обработка `origin` через one-hot обязательна (категория, а не “число 1/2/3”).\n",
    "2. Подбор `max_depth`, `min_samples_leaf`, `max_features`, `n_estimators` снизит RMSE/MAE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cf0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (classification): {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "CV best f1_macro: 0.995390423269211\n",
      "Improved (classification): {'accuracy': 0.9963636363636363, 'f1_macro': 0.9963198394111743, 'roc_auc': 1.0}\n",
      "Best params (regression): {'model__bootstrap': True, 'model__max_depth': 10, 'model__max_features': 'log2', 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 700}\n",
      "CV best (neg RMSE): -2.9013398524118506\n",
      "Improved (regression): {'mae': 1.5744949690451264, 'rmse': 2.1357032800011164, 'r2': 0.915165888199412}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>improved</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.578846</td>\n",
       "      <td>2.157382</td>\n",
       "      <td>0.913435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.574495</td>\n",
       "      <td>2.135703</td>\n",
       "      <td>0.915166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task     stage  accuracy  f1_macro  roc_auc       mae      rmse  \\\n",
       "0  classification  baseline  0.996364   0.99632      1.0       NaN       NaN   \n",
       "1  classification  improved  0.996364   0.99632      1.0       NaN       NaN   \n",
       "2      regression  baseline       NaN       NaN      NaN  1.578846  2.157382   \n",
       "3      regression  improved       NaN       NaN      NaN  1.574495  2.135703   \n",
       "\n",
       "         r2  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2  0.913435  \n",
       "3  0.915166  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Improved: Classification (GridSearchCV) =====\n",
    "cls_param_grid = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [None, 3, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "cv_cls = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cls_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    cls_param_grid,\n",
    "    cv=cv_cls,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "cls_search.fit(X_cls_train, y_cls_train)\n",
    "\n",
    "print(\"Best params (classification):\", cls_search.best_params_)\n",
    "print(\"CV best f1_macro:\", cls_search.best_score_)\n",
    "\n",
    "rfc_best = cls_search.best_estimator_\n",
    "y_cls_pred_best = rfc_best.predict(X_cls_test)\n",
    "y_cls_proba_best = rfc_best.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_best = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_best),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_best, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_best),\n",
    "}\n",
    "print(\"Improved (classification):\", cls_metrics_best)\n",
    "\n",
    "\n",
    "# ===== Improved: Regression (preprocess + GridSearchCV) =====\n",
    "reg_preprocess = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", make_ohe_dense(), cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    (\"prep\", reg_preprocess),\n",
    "    (\"model\", RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1))\n",
    "])\n",
    "\n",
    "reg_param_grid = {\n",
    "    \"model__n_estimators\": [300, 700],\n",
    "    \"model__max_depth\": [None, 5, 10, 20],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 5],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", 1.0],\n",
    "    \"model__bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "reg_search = GridSearchCV(\n",
    "    reg_pipe,\n",
    "    reg_param_grid,\n",
    "    cv=cv_reg,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "reg_search.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "print(\"Best params (regression):\", reg_search.best_params_)\n",
    "print(\"CV best (neg RMSE):\", reg_search.best_score_)\n",
    "\n",
    "rfr_best = reg_search.best_estimator_\n",
    "y_reg_pred_best = rfr_best.predict(X_reg_test)\n",
    "\n",
    "reg_metrics_best = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_best),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_best),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_best),\n",
    "}\n",
    "print(\"Improved (regression):\", reg_metrics_best)\n",
    "\n",
    "\n",
    "compare = pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"stage\": \"baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"improved\", **cls_metrics_best},\n",
    "    {\"task\": \"regression\", \"stage\": \"baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"improved\", **reg_metrics_best},\n",
    "])\n",
    "display(compare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7602a",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Имплементация Random Forest (с нуля)\n",
    "\n",
    "Сделаем упрощённую реализацию Random Forest:\n",
    "- строим много деревьев на bootstrap-выборках;\n",
    "- в каждом узле выбираем случайное подмножество признаков (`max_features`) и ищем лучший сплит только по ним;\n",
    "- **классификация:** голосование большинством / усреднение вероятностей;\n",
    "- **регрессия:** усреднение предсказаний.\n",
    "\n",
    "> Реализация написана на NumPy и Python для учебных целей (будет медленнее sklearn).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128da584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _gini(counts: np.ndarray) -> float:\n",
    "    total = counts.sum()\n",
    "    if total <= 0:\n",
    "        return 0.0\n",
    "    p = counts / total\n",
    "    return float(1.0 - np.sum(p ** 2))\n",
    "\n",
    "def _entropy(counts: np.ndarray) -> float:\n",
    "    total = counts.sum()\n",
    "    if total <= 0:\n",
    "        return 0.0\n",
    "    p = counts / total\n",
    "    p = p[p > 0]\n",
    "    return float(-np.sum(p * np.log2(p)))\n",
    "\n",
    "def _mse_from_sums(sum_y: float, sum_y2: float, n: int) -> float:\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    mean = sum_y / n\n",
    "    return float(sum_y2 / n - mean * mean)\n",
    "\n",
    "@dataclass\n",
    "class _NodeC:\n",
    "    feature: Optional[int] = None\n",
    "    threshold: Optional[float] = None\n",
    "    left: Optional[\"__class__\"] = None\n",
    "    right: Optional[\"__class__\"] = None\n",
    "    # leaf:\n",
    "    class_counts: Optional[np.ndarray] = None  # (n_classes,)\n",
    "\n",
    "@dataclass\n",
    "class _NodeR:\n",
    "    feature: Optional[int] = None\n",
    "    threshold: Optional[float] = None\n",
    "    left: Optional[\"__class__\"] = None\n",
    "    right: Optional[\"__class__\"] = None\n",
    "    value: Optional[float] = None  # mean in leaf\n",
    "\n",
    "\n",
    "class DecisionTreeClassifierRF:\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: int = 2,\n",
    "                 min_samples_leaf: int = 1,\n",
    "                 criterion: Literal[\"gini\", \"entropy\"] = \"gini\",\n",
    "                 max_features: Optional[int] = None,\n",
    "                 random_state: Optional[int] = None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = int(min_samples_split)\n",
    "        self.min_samples_leaf = int(min_samples_leaf)\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        self.rng_ = np.random.default_rng(random_state)\n",
    "        self.root_ = None\n",
    "        self.classes_ = None\n",
    "        self.n_features_ = None\n",
    "        self.n_classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=int)\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.classes_, y_enc = np.unique(y, return_inverse=True)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        self.root_ = self._build(X, y_enc, depth=0)\n",
    "        return self\n",
    "\n",
    "    def _impurity(self, counts):\n",
    "        return _gini(counts) if self.criterion == \"gini\" else _entropy(counts)\n",
    "\n",
    "    def _feature_subset(self):\n",
    "        if self.max_features is None or self.max_features >= self.n_features_:\n",
    "            return np.arange(self.n_features_)\n",
    "        return self.rng_.choice(self.n_features_, size=self.max_features, replace=False)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        n, d = X.shape\n",
    "        total_counts = np.bincount(y, minlength=self.n_classes_).astype(float)\n",
    "\n",
    "        best_imp = float(\"inf\")\n",
    "        best_f = None\n",
    "        best_thr = None\n",
    "\n",
    "        feat_idx = self._feature_subset()\n",
    "\n",
    "        for f in feat_idx:\n",
    "            xs = X[:, f]\n",
    "            order = np.argsort(xs, kind=\"mergesort\")\n",
    "            xs_sorted = xs[order]\n",
    "            y_sorted = y[order]\n",
    "\n",
    "            diffs = xs_sorted[1:] != xs_sorted[:-1]\n",
    "            if not np.any(diffs):\n",
    "                continue\n",
    "\n",
    "            left_counts = np.zeros((n - 1, self.n_classes_), dtype=float)\n",
    "            running = np.zeros(self.n_classes_, dtype=float)\n",
    "            for i in range(n - 1):\n",
    "                running[y_sorted[i]] += 1.0\n",
    "                left_counts[i] = running\n",
    "\n",
    "            right_counts = total_counts - left_counts\n",
    "            left_n = np.arange(1, n)\n",
    "            right_n = n - left_n\n",
    "\n",
    "            valid = diffs & (left_n >= self.min_samples_leaf) & (right_n >= self.min_samples_leaf)\n",
    "            if not np.any(valid):\n",
    "                continue\n",
    "\n",
    "            imp_left = np.array([self._impurity(c) for c in left_counts])\n",
    "            imp_right = np.array([self._impurity(c) for c in right_counts])\n",
    "            weighted = (left_n * imp_left + right_n * imp_right) / n\n",
    "            weighted[~valid] = np.inf\n",
    "\n",
    "            i_best = int(np.argmin(weighted))\n",
    "            if weighted[i_best] < best_imp:\n",
    "                best_imp = float(weighted[i_best])\n",
    "                best_f = int(f)\n",
    "                best_thr = float((xs_sorted[i_best] + xs_sorted[i_best + 1]) / 2.0)\n",
    "\n",
    "        return best_f, best_thr\n",
    "\n",
    "    def _make_leaf(self, y):\n",
    "        counts = np.bincount(y, minlength=self.n_classes_).astype(float)\n",
    "        return _NodeC(class_counts=counts)\n",
    "\n",
    "    def _build(self, X, y, depth):\n",
    "        n = X.shape[0]\n",
    "\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or            (n < self.min_samples_split) or            (len(np.unique(y)) == 1):\n",
    "            return self._make_leaf(y)\n",
    "\n",
    "        f, thr = self._best_split(X, y)\n",
    "        if f is None:\n",
    "            return self._make_leaf(y)\n",
    "\n",
    "        left_mask = X[:, f] <= thr\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
    "            return self._make_leaf(y)\n",
    "\n",
    "        node = _NodeC(feature=f, threshold=thr)\n",
    "        node.left = self._build(X[left_mask], y[left_mask], depth + 1)\n",
    "        node.right = self._build(X[right_mask], y[right_mask], depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _leaf_counts(self, x, node: _NodeC):\n",
    "        while node.feature is not None:\n",
    "            node = node.left if x[node.feature] <= node.threshold else node.right\n",
    "        return node.class_counts\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        probs = []\n",
    "        for x in X:\n",
    "            counts = self._leaf_counts(x, self.root_)\n",
    "            p = counts / (counts.sum() + 1e-12)\n",
    "            probs.append(p)\n",
    "        probs = np.vstack(probs)\n",
    "        # to original class order (already 0..k-1)\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        pred_enc = np.argmax(proba, axis=1)\n",
    "        return self.classes_[pred_enc]\n",
    "\n",
    "\n",
    "class DecisionTreeRegressorRF:\n",
    "    def __init__(self,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: int = 2,\n",
    "                 min_samples_leaf: int = 1,\n",
    "                 max_features: Optional[int] = None,\n",
    "                 random_state: Optional[int] = None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = int(min_samples_split)\n",
    "        self.min_samples_leaf = int(min_samples_leaf)\n",
    "        self.max_features = max_features\n",
    "        self.rng_ = np.random.default_rng(random_state)\n",
    "        self.root_ = None\n",
    "        self.n_features_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.root_ = self._build(X, y, depth=0)\n",
    "        return self\n",
    "\n",
    "    def _feature_subset(self):\n",
    "        if self.max_features is None or self.max_features >= self.n_features_:\n",
    "            return np.arange(self.n_features_)\n",
    "        return self.rng_.choice(self.n_features_, size=self.max_features, replace=False)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        n, d = X.shape\n",
    "        best_loss = float(\"inf\")\n",
    "        best_f = None\n",
    "        best_thr = None\n",
    "\n",
    "        total_sum = float(np.sum(y))\n",
    "        total_sum2 = float(np.sum(y ** 2))\n",
    "\n",
    "        feat_idx = self._feature_subset()\n",
    "\n",
    "        for f in feat_idx:\n",
    "            xs = X[:, f]\n",
    "            order = np.argsort(xs, kind=\"mergesort\")\n",
    "            xs_sorted = xs[order]\n",
    "            y_sorted = y[order]\n",
    "\n",
    "            diffs = xs_sorted[1:] != xs_sorted[:-1]\n",
    "            if not np.any(diffs):\n",
    "                continue\n",
    "\n",
    "            prefix_sum = np.cumsum(y_sorted[:-1])\n",
    "            prefix_sum2 = np.cumsum((y_sorted[:-1]) ** 2)\n",
    "\n",
    "            left_n = np.arange(1, n)\n",
    "            right_n = n - left_n\n",
    "\n",
    "            right_sum = total_sum - prefix_sum\n",
    "            right_sum2 = total_sum2 - prefix_sum2\n",
    "\n",
    "            valid = diffs & (left_n >= self.min_samples_leaf) & (right_n >= self.min_samples_leaf)\n",
    "            if not np.any(valid):\n",
    "                continue\n",
    "\n",
    "            left_mse = np.array([_mse_from_sums(prefix_sum[i], prefix_sum2[i], int(left_n[i])) for i in range(n - 1)])\n",
    "            right_mse = np.array([_mse_from_sums(right_sum[i], right_sum2[i], int(right_n[i])) for i in range(n - 1)])\n",
    "            weighted = (left_n * left_mse + right_n * right_mse) / n\n",
    "            weighted[~valid] = np.inf\n",
    "\n",
    "            i_best = int(np.argmin(weighted))\n",
    "            if weighted[i_best] < best_loss:\n",
    "                best_loss = float(weighted[i_best])\n",
    "                best_f = int(f)\n",
    "                best_thr = float((xs_sorted[i_best] + xs_sorted[i_best + 1]) / 2.0)\n",
    "\n",
    "        return best_f, best_thr\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        return float(np.mean(y)) if y.size else 0.0\n",
    "\n",
    "    def _build(self, X, y, depth):\n",
    "        n = X.shape[0]\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or            (n < self.min_samples_split) or            (n <= 2 * self.min_samples_leaf):\n",
    "            return _NodeR(value=self._leaf_value(y))\n",
    "\n",
    "        f, thr = self._best_split(X, y)\n",
    "        if f is None:\n",
    "            return _NodeR(value=self._leaf_value(y))\n",
    "\n",
    "        left_mask = X[:, f] <= thr\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
    "            return _NodeR(value=self._leaf_value(y))\n",
    "\n",
    "        node = _NodeR(feature=f, threshold=thr)\n",
    "        node.left = self._build(X[left_mask], y[left_mask], depth + 1)\n",
    "        node.right = self._build(X[right_mask], y[right_mask], depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict_one(self, x, node: _NodeR):\n",
    "        while node.feature is not None:\n",
    "            node = node.left if x[node.feature] <= node.threshold else node.right\n",
    "        return node.value\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return np.array([self._predict_one(x, self.root_) for x in X], dtype=float)\n",
    "\n",
    "\n",
    "class RandomForestClassifierCustom:\n",
    "    def __init__(self,\n",
    "                 n_estimators: int = 100,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: int = 2,\n",
    "                 min_samples_leaf: int = 1,\n",
    "                 criterion: Literal[\"gini\", \"entropy\"] = \"gini\",\n",
    "                 max_features: Optional[Literal[\"sqrt\",\"log2\", int]] = \"sqrt\",\n",
    "                 bootstrap: bool = True,\n",
    "                 random_state: Optional[int] = None):\n",
    "        self.n_estimators = int(n_estimators)\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = int(min_samples_split)\n",
    "        self.min_samples_leaf = int(min_samples_leaf)\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bool(bootstrap)\n",
    "        self.rng_ = np.random.default_rng(random_state)\n",
    "        self.trees_ = []\n",
    "        self.classes_ = None\n",
    "\n",
    "    def _resolve_max_features(self, n_features: int) -> int:\n",
    "        mf = self.max_features\n",
    "        if mf is None:\n",
    "            return n_features\n",
    "        if mf == \"sqrt\":\n",
    "            return max(1, int(np.sqrt(n_features)))\n",
    "        if mf == \"log2\":\n",
    "            return max(1, int(np.log2(n_features)))\n",
    "        if isinstance(mf, int):\n",
    "            return max(1, min(n_features, mf))\n",
    "        raise ValueError(\"Unsupported max_features\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=int)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "        n, d = X.shape\n",
    "        max_feat_n = self._resolve_max_features(d)\n",
    "        self.trees_ = []\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                idx = self.rng_.integers(0, n, size=n)\n",
    "            else:\n",
    "                idx = np.arange(n)\n",
    "\n",
    "            tree = DecisionTreeClassifierRF(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                criterion=self.criterion,\n",
    "                max_features=max_feat_n,\n",
    "                random_state=int(self.rng_.integers(0, 1_000_000_000))\n",
    "            )\n",
    "            tree.fit(X[idx], y[idx])\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        probs = None\n",
    "        for t in self.trees_:\n",
    "            p = t.predict_proba(X)  # (n, n_classes)\n",
    "            probs = p if probs is None else (probs + p)\n",
    "        probs = probs / max(1, len(self.trees_))\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        pred_enc = np.argmax(proba, axis=1)\n",
    "        # tree classes are encoded from 0..k-1, and original dataset is 0/1\n",
    "        return pred_enc.astype(int)\n",
    "\n",
    "\n",
    "class RandomForestRegressorCustom:\n",
    "    def __init__(self,\n",
    "                 n_estimators: int = 100,\n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_split: int = 2,\n",
    "                 min_samples_leaf: int = 1,\n",
    "                 max_features: Optional[Literal[\"sqrt\",\"log2\", int]] = \"sqrt\",\n",
    "                 bootstrap: bool = True,\n",
    "                 random_state: Optional[int] = None):\n",
    "        self.n_estimators = int(n_estimators)\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = int(min_samples_split)\n",
    "        self.min_samples_leaf = int(min_samples_leaf)\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bool(bootstrap)\n",
    "        self.rng_ = np.random.default_rng(random_state)\n",
    "        self.trees_ = []\n",
    "\n",
    "    def _resolve_max_features(self, n_features: int) -> int:\n",
    "        mf = self.max_features\n",
    "        if mf is None:\n",
    "            return n_features\n",
    "        if mf == \"sqrt\":\n",
    "            return max(1, int(np.sqrt(n_features)))\n",
    "        if mf == \"log2\":\n",
    "            return max(1, int(np.log2(n_features)))\n",
    "        if isinstance(mf, int):\n",
    "            return max(1, min(n_features, mf))\n",
    "        raise ValueError(\"Unsupported max_features\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        n, d = X.shape\n",
    "        max_feat_n = self._resolve_max_features(d)\n",
    "        self.trees_ = []\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                idx = self.rng_.integers(0, n, size=n)\n",
    "            else:\n",
    "                idx = np.arange(n)\n",
    "\n",
    "            tree = DecisionTreeRegressorRF(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                max_features=max_feat_n,\n",
    "                random_state=int(self.rng_.integers(0, 1_000_000_000))\n",
    "            )\n",
    "            tree.fit(X[idx], y[idx])\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        preds = np.zeros(X.shape[0], dtype=float)\n",
    "        for t in self.trees_:\n",
    "            preds += t.predict(X)\n",
    "        preds /= max(1, len(self.trees_))\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d981b1",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Кастомные модели vs бейзлайн (пункт 2)\n",
    "\n",
    "Для честного сравнения:\n",
    "- **Классификация:** используем те же исходные признаки (как в sklearn-бейзлайне).\n",
    "- **Регрессия:** используем тот же препроцессинг (импутация + one-hot origin), потому что в данных есть пропуски и категориальный признак.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36178018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom baseline (classification): {'accuracy': 0.9963636363636363, 'f1_macro': 0.9963198394111743, 'roc_auc': 1.0}\n",
      "Custom baseline (regression): {'mae': 1.6286431500652658, 'rmse': 2.124097960371601, 'r2': 0.9160853530459732}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.578846</td>\n",
       "      <td>2.157382</td>\n",
       "      <td>0.913435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.628643</td>\n",
       "      <td>2.124098</td>\n",
       "      <td>0.916085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task             model  accuracy  f1_macro  roc_auc       mae  \\\n",
       "0  classification  sklearn_baseline  0.996364   0.99632      1.0       NaN   \n",
       "1  classification   custom_baseline  0.996364   0.99632      1.0       NaN   \n",
       "2      regression  sklearn_baseline       NaN       NaN      NaN  1.578846   \n",
       "3      regression   custom_baseline       NaN       NaN      NaN  1.628643   \n",
       "\n",
       "       rmse        r2  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2  2.157382  0.913435  \n",
       "3  2.124098  0.916085  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Custom baseline: classification =====\n",
    "# (для скорости оставим меньше деревьев, чем в sklearn)\n",
    "custom_rfc = RandomForestClassifierCustom(\n",
    "    n_estimators=60,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    criterion=\"gini\",\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    random_state=RANDOM_STATE\n",
    ").fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred_c = custom_rfc.predict(X_cls_test)\n",
    "y_cls_proba_c = custom_rfc.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_custom_base = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_c),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_c, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_c),\n",
    "}\n",
    "print(\"Custom baseline (classification):\", cls_metrics_custom_base)\n",
    "\n",
    "# ===== Custom baseline: regression (same preprocess as baseline) =====\n",
    "X_reg_train_p = reg_preprocess_base.fit_transform(X_reg_train)\n",
    "X_reg_test_p = reg_preprocess_base.transform(X_reg_test)\n",
    "\n",
    "custom_rfr = RandomForestRegressorCustom(\n",
    "    n_estimators=80,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    random_state=RANDOM_STATE\n",
    ").fit(X_reg_train_p, y_reg_train.values)\n",
    "\n",
    "y_reg_pred_c = custom_rfr.predict(X_reg_test_p)\n",
    "\n",
    "reg_metrics_custom_base = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_c),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_c),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_c),\n",
    "}\n",
    "print(\"Custom baseline (regression):\", reg_metrics_custom_base)\n",
    "\n",
    "display(pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"model\": \"sklearn_baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"model\": \"custom_baseline\", **cls_metrics_custom_base},\n",
    "    {\"task\": \"regression\", \"model\": \"sklearn_baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"model\": \"custom_baseline\", **reg_metrics_custom_base},\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878250c",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Добавляем техники улучшенного бейзлайна (пункт 3) к кастомным моделям\n",
    "\n",
    "Берём лучшие гиперпараметры из GridSearchCV и применяем их к кастомной реализации.\n",
    "\n",
    "> Важно: в sklearn GridSearch мог выбрать очень большое `n_estimators` (например 700).  \n",
    "> В кастомной реализации для скорости ограничим `n_estimators` сверху (например 120), сохранив остальные параметры.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2f5e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom improved (classification): {'accuracy': 0.9963636363636363, 'f1_macro': 0.9963198394111743, 'roc_auc': 1.0}\n",
      "Custom improved (regression): {'mae': 1.5367794713790723, 'rmse': 2.0979930929170973, 'r2': 0.9181352771183077}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>sklearn_improved</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classification</td>\n",
       "      <td>custom_improved</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.578846</td>\n",
       "      <td>2.157382</td>\n",
       "      <td>0.913435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>regression</td>\n",
       "      <td>sklearn_improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.574495</td>\n",
       "      <td>2.135703</td>\n",
       "      <td>0.915166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.628643</td>\n",
       "      <td>2.124098</td>\n",
       "      <td>0.916085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regression</td>\n",
       "      <td>custom_improved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.536779</td>\n",
       "      <td>2.097993</td>\n",
       "      <td>0.918135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task             stage  accuracy  f1_macro  roc_auc       mae  \\\n",
       "0  classification  sklearn_baseline  0.996364   0.99632      1.0       NaN   \n",
       "1  classification  sklearn_improved  0.996364   0.99632      1.0       NaN   \n",
       "2  classification   custom_baseline  0.996364   0.99632      1.0       NaN   \n",
       "3  classification   custom_improved  0.996364   0.99632      1.0       NaN   \n",
       "4      regression  sklearn_baseline       NaN       NaN      NaN  1.578846   \n",
       "5      regression  sklearn_improved       NaN       NaN      NaN  1.574495   \n",
       "6      regression   custom_baseline       NaN       NaN      NaN  1.628643   \n",
       "7      regression   custom_improved       NaN       NaN      NaN  1.536779   \n",
       "\n",
       "       rmse        r2  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4  2.157382  0.913435  \n",
       "5  2.135703  0.915166  \n",
       "6  2.124098  0.916085  \n",
       "7  2.097993  0.918135  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ===== Custom improved: classification (best params) =====\n",
    "bp = cls_search.best_params_.copy()\n",
    "\n",
    "best_n_estimators_cls = int(bp.get(\"n_estimators\", 200))\n",
    "best_n_estimators_cls = min(best_n_estimators_cls, 120)\n",
    "\n",
    "best_max_depth_cls = bp.get(\"max_depth\", None)\n",
    "best_min_split_cls = int(bp.get(\"min_samples_split\", 2))\n",
    "best_min_leaf_cls = int(bp.get(\"min_samples_leaf\", 1))\n",
    "best_max_features_cls = bp.get(\"max_features\", \"sqrt\")\n",
    "best_bootstrap_cls = bool(bp.get(\"bootstrap\", True))\n",
    "\n",
    "custom_rfc_best = RandomForestClassifierCustom(\n",
    "    n_estimators=best_n_estimators_cls,\n",
    "    max_depth=best_max_depth_cls,\n",
    "    min_samples_split=best_min_split_cls,\n",
    "    min_samples_leaf=best_min_leaf_cls,\n",
    "    criterion=\"gini\",  # критерий в кастом-дереве задан gini/entropy; оставим gini (или можно расширить)\n",
    "    max_features=(\"sqrt\" if best_max_features_cls == \"sqrt\" else (\"log2\" if best_max_features_cls == \"log2\" else None)),\n",
    "    bootstrap=best_bootstrap_cls,\n",
    "    random_state=RANDOM_STATE\n",
    ").fit(X_cls_train, y_cls_train)\n",
    "\n",
    "y_cls_pred_cb = custom_rfc_best.predict(X_cls_test)\n",
    "y_cls_proba_cb = custom_rfc_best.predict_proba(X_cls_test)[:, 1]\n",
    "\n",
    "cls_metrics_custom_improved = {\n",
    "    \"accuracy\": accuracy_score(y_cls_test, y_cls_pred_cb),\n",
    "    \"f1_macro\": f1_score(y_cls_test, y_cls_pred_cb, average=\"macro\"),\n",
    "    \"roc_auc\": roc_auc_score(y_cls_test, y_cls_proba_cb),\n",
    "}\n",
    "print(\"Custom improved (classification):\", cls_metrics_custom_improved)\n",
    "\n",
    "\n",
    "# ===== Custom improved: regression (best params + same preprocess) =====\n",
    "bp_r = reg_search.best_params_.copy()\n",
    "best_n_estimators_reg = int(bp_r.get(\"model__n_estimators\", 300))\n",
    "best_n_estimators_reg = min(best_n_estimators_reg, 160)\n",
    "\n",
    "best_max_depth_reg = bp_r.get(\"model__max_depth\", None)\n",
    "best_min_split_reg = int(bp_r.get(\"model__min_samples_split\", 2))\n",
    "best_min_leaf_reg = int(bp_r.get(\"model__min_samples_leaf\", 1))\n",
    "best_max_features_reg = bp_r.get(\"model__max_features\", \"sqrt\")\n",
    "best_bootstrap_reg = bool(bp_r.get(\"model__bootstrap\", True))\n",
    "\n",
    "# те же преобразования, что и в improved пайплайне\n",
    "X_reg_train_pp = reg_preprocess.fit_transform(X_reg_train)\n",
    "X_reg_test_pp = reg_preprocess.transform(X_reg_test)\n",
    "\n",
    "custom_rfr_best = RandomForestRegressorCustom(\n",
    "    n_estimators=best_n_estimators_reg,\n",
    "    max_depth=best_max_depth_reg,\n",
    "    min_samples_split=best_min_split_reg,\n",
    "    min_samples_leaf=best_min_leaf_reg,\n",
    "    max_features=(\"sqrt\" if best_max_features_reg == \"sqrt\" else (\"log2\" if best_max_features_reg == \"log2\" else None)),\n",
    "    bootstrap=best_bootstrap_reg,\n",
    "    random_state=RANDOM_STATE\n",
    ").fit(X_reg_train_pp, y_reg_train.values)\n",
    "\n",
    "y_reg_pred_cb = custom_rfr_best.predict(X_reg_test_pp)\n",
    "\n",
    "reg_metrics_custom_improved = {\n",
    "    \"mae\": mean_absolute_error(y_reg_test, y_reg_pred_cb),\n",
    "    \"rmse\": rmse(y_reg_test, y_reg_pred_cb),\n",
    "    \"r2\": r2_score(y_reg_test, y_reg_pred_cb),\n",
    "}\n",
    "print(\"Custom improved (regression):\", reg_metrics_custom_improved)\n",
    "\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"task\": \"classification\", \"stage\": \"sklearn_baseline\", **cls_metrics_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"sklearn_improved\", **cls_metrics_best},\n",
    "    {\"task\": \"classification\", \"stage\": \"custom_baseline\", **cls_metrics_custom_base},\n",
    "    {\"task\": \"classification\", \"stage\": \"custom_improved\", **cls_metrics_custom_improved},\n",
    "\n",
    "    {\"task\": \"regression\", \"stage\": \"sklearn_baseline\", **reg_metrics_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"sklearn_improved\", **reg_metrics_best},\n",
    "    {\"task\": \"regression\", \"stage\": \"custom_baseline\", **reg_metrics_custom_base},\n",
    "    {\"task\": \"regression\", \"stage\": \"custom_improved\", **reg_metrics_custom_improved},\n",
    "])\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a04b6",
   "metadata": {},
   "source": [
    "\n",
    "## Выводы (кратко по пунктам)\n",
    "\n",
    "**Классификация:**\n",
    "1. Random Forest обычно устойчивее одного дерева, потому что усредняет множество независимых деревьев.\n",
    "2. Подбор `max_depth/min_samples_leaf/min_samples_split` уменьшает переобучение и улучшает качество на тесте.\n",
    "3. `max_features` влияет на разнообразие деревьев - часто даёт прирост при `sqrt/log2`.\n",
    "4. Кастомная реализация (bagging + случайные признаки в узлах) воспроизводит основной принцип Random Forest и даёт сопоставимые метрики (но может быть медленнее и отличаться из-за деталей реализации).\n",
    "\n",
    "**Регрессия:**\n",
    "1. Импутация `horsepower` обязательна из-за пропусков.\n",
    "2. One-hot для `origin` улучшает качество, потому что `origin` - категориальный признак.\n",
    "3. Подбор гиперпараметров леса даёт снижение RMSE/MAE и рост R².\n",
    "4. Кастомный лес на тех же преобразованных признаках даёт близкие результаты, но обычно проигрывает по скорости и иногда по качеству из-за более простых эвристик.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
